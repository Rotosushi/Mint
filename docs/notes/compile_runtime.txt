// Copyright (C) 2023 Cade Weinberg
// 
// This file is part of Mint.
// 
// Mint is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
// 
// Mint is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
// 
// You should have received a copy of the GNU General Public License
// along with Mint.  If not, see <http://www.gnu.org/licenses/>.

"anything that can be done at compile time is done at compile time"

Compile time (Comptime) is in essence interpreted. 
Runtime is in essence generated assembly.

so, what can be done at compile time, and what cannot?

Theoretically it is possible to interpret any information which 
is known at compile time. And Definitions must be made available 
to the comptime, for the runtime to make any sense at all.

the important thing to consider is what happens to a term which 
cannot be evaluated, only compiled. Due to that terms reliance upon 
data which is only knowable at runtime.

Comptime:
  Definitions
    Let 
    Module, Import 

  Expressions 
    Variables
    Binops 
    Unops

  Types 
    Nil 
    Boolean 
    Integer
    Lambda

  Values 
    nil 
    true, false 
    [0-9]+
    lambda-literals

Runtime:
  Definitions 
    Let 
    Module, Import
    lambda-definitions

okay, all currently implemented values are scalars.
at comptime values are represented as Ast nodes.
at runtime values are represented as their equivalent llvm::Values.
at runtime:
  Nil     -> llvm::ConstantInt(1, false)
  Boolean -> llvm::ConstantInt(1, value)
  Integer -> llvm::ConstantInt(32, value)
  Lambda  -> llvm::Function * 

note that lambdas are represented as function pointers.
this can be done because there is no way to specify a capture 
on a lambda.

next to translate are the syntax ast's, 
these can just pass through at comptime and runtime.

next are expressions:
at comptime expressions operate on Asts
at runtime expressions operator on llvm::Values
at runtime:
  Binop  -> BinopCodegenFn(llvm::Value *, llvm::Value *, Environment &)
  Unop   -> UnopCodegenFn(llvm::Value *, Environment &)
  Variable -> Bindings stores a llvm::Value * that is retrieved,
              if the variable is use-before-def of the runtime value 
              that needs to be handled the same as we handle use-before-def 
              of the comptime value.

next are definitions:
at comptime definitions bind Types and Asts and comptime values.
at runtime definitions bind global or local variables.
at runtime:
  Let -> must create a global variable within the module.
         and needs to convert the qualified name 
         to something that llvm accepts.
         (convert any "::" to ".")

next are statements:
at comptime statements operate on Asts 
at runtime statements operate on llvm::Values 
at runtime:
  Import -> is a no-op, as evaluation brought all definitions into 
            the current environment already. so as long as codegen 
            is done after we fully typecheck and evaluate all source 
            code, we will codegen anything that the import statement 
            would bring in.
  Module -> needs to codegen each of it's subexpressions.
            and handle any use-before-def as usual.


-----------------------------------------------------------------------------------
currently the evaluation strategy operates directly on Ast's. 
this is inefficient.
because the nodes of an Ast are allocated on the heap,

there are two ways I can think of for changing this,
1) translate the Ast to a custom IR and evaluate that.
  this IR can be designed for speed. 
  (ideally stored in one big array, or as a "std::deque" like 
  structure, where constructs bigger than a single instruction 
  are themselves pointers to an array of instructions.)
  and this IR is then translated to LLVM IR for codegen.

2) translate the Ast to LLVM IR and use a JIT for evaluation.
  this has the advantage of running directly on the CPU so 
  it is the fastest it could be. additionally it saves the 
  compiler from defining two translation steps.
  and it reduces the amount of code that the compiler itself 
  needs to get right in order to have the semantics of the compiler.
  downsides are that Semantic analysis still occurs on Ast's directly,
  which is slow. and I lose out on the fun of designing yet another IR. :P